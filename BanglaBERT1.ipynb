{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEmoC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from transformers import BertForSequenceClassification,BertTokenizer\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "model = BertForSequenceClassification.from_pretrained(\"sagorsarker/bangla-bert-base\", num_labels=6)\n",
    "tokenizer = BertTokenizer.from_pretrained('sagorsarker/bangla-bert-base')\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_excel('bemoc.xlsx')\n",
    "corpus = df['TEXT'].to_list()\n",
    "y=df['classes']\n",
    "end = 5600\n",
    "train_texts = corpus[0:end]\n",
    "test_texts = corpus[end:]\n",
    "train_labels = y[0:end].to_list()\n",
    "test_labels = y[end:].to_list()\n",
    "#texts = df[\"t\"]\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.1, random_state=42)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_labels)\n",
    "val_labels = label_encoder.transform(val_labels)\n",
    "test_labels = label_encoder.transform(test_labels)\n",
    "\n",
    "# Tokenization\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=140)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=140)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=140)\n",
    "\n",
    "# Convert to PyTorch datasets\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = EmotionDataset(train_encodings, train_labels)\n",
    "val_dataset = EmotionDataset(val_encodings, val_labels)\n",
    "test_dataset = EmotionDataset(test_encodings, test_labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define model\n",
    "num_labels = len(np.unique(train_labels))\n",
    "\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "epochs = 20\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "total_steps = len(train_loader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optim, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "def train(model, loader, optim, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device).long()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted_labels = torch.max(outputs.logits, dim=1)\n",
    "        correct_predictions += (predicted_labels == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    return total_loss / len(loader), accuracy\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    total_loss = 0.0  # Initialize total loss\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Assume that model's output is a sequence classifier output with loss stored as outputs.loss\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()  # Accumulate the loss\n",
    "\n",
    "            # Convert predictions and labels for accuracy calculation\n",
    "            predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(loader)  # Calculate average loss\n",
    "    accuracy = accuracy_score(true_labels, predictions)  # Calculate accuracy\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "for epoch in range(epochs): \n",
    "    train_loss, train_accuracy = train(model, train_loader, optim, scheduler)\n",
    "    print(f'Epoch {epoch + 1}, Train_Loss: {round(train_loss,4)}, Train_Accuracy: {round(train_accuracy,4)}', end=\", \")\n",
    "\n",
    "    valid_loss, val_accuracy = evaluate(model, val_loader)\n",
    "    print(f'Val_Loss: {round(valid_loss,4)}, Val_Accuracy: {round(val_accuracy,4)}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Evaluate model\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].numpy()  # CPU\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
    "            true_labels.extend(labels)\n",
    "\n",
    "    return predictions, true_labels\n",
    "\n",
    "# Get predictions and true labels\n",
    "predictions, true_labels = evaluate(model, test_loader)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "\n",
    "# Create a pandas DataFrame from the confusion matrix\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=class_names, columns=class_names)\n",
    "\n",
    "# Display the confusion matrix as a DataFrame with class names as labels\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(conf_matrix_df)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predictions, target_names=class_names))\n",
    "import seaborn as sn\n",
    "y_true=['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise']\n",
    "data = conf_matrix\n",
    "df_cm = pd.DataFrame(data, columns=np.unique(y_true), index = np.unique(y_true))\n",
    "sn.set(font_scale=2)#for label size\n",
    "sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 24}, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing Data - BEMoC + banglaemotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import BertForSequenceClassification,BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('sagorsarker/bangla-bert-base')\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"sagorsarker/bangla-bert-base\", num_labels=6)\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "df=pd.read_csv(\"merged.csv\")\n",
    "corpus = df['text'].to_list()\n",
    "y=df['class']\n",
    "end = 11240\n",
    "train_texts = corpus[0:end]\n",
    "test_texts = corpus[end:]\n",
    "train_labels = y[0:end].to_list()\n",
    "test_labels = y[end:].to_list()\n",
    "#texts = df[\"t\"]\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.1, random_state=42)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_labels)\n",
    "val_labels = label_encoder.transform(val_labels)\n",
    "test_labels = label_encoder.transform(test_labels)\n",
    "\n",
    "# Tokenization\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=140)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=140)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=140)\n",
    "\n",
    "# Convert to PyTorch datasets\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = EmotionDataset(train_encodings, train_labels)\n",
    "val_dataset = EmotionDataset(val_encodings, val_labels)\n",
    "test_dataset = EmotionDataset(test_encodings, test_labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define model\n",
    "num_labels = len(np.unique(train_labels))\n",
    "\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "epochs = 20\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "total_steps = len(train_loader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optim, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "def train(model, loader, optim, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device).long()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted_labels = torch.max(outputs.logits, dim=1)\n",
    "        correct_predictions += (predicted_labels == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    return total_loss / len(loader), accuracy\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    total_loss = 0.0  # Initialize total loss\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Assume that model's output is a sequence classifier output with loss stored as outputs.loss\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()  # Accumulate the loss\n",
    "\n",
    "            # Convert predictions and labels for accuracy calculation\n",
    "            predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(loader)  # Calculate average loss\n",
    "    accuracy = accuracy_score(true_labels, predictions)  # Calculate accuracy\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "for epoch in range(epochs): \n",
    "    train_loss, train_accuracy = train(model, train_loader, optim, scheduler)\n",
    "    print(f'Epoch {epoch + 1}, Train_Loss: {round(train_loss,4)}, Train_Accuracy: {round(train_accuracy,4)}', end=\", \")\n",
    "\n",
    "    valid_loss, val_accuracy = evaluate(model, val_loader)\n",
    "    print(f'Val_Loss: {round(valid_loss,4)}, Val_Accuracy: {round(val_accuracy,4)}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Evaluate model\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].numpy()  # CPU\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
    "            true_labels.extend(labels)\n",
    "\n",
    "    return predictions, true_labels\n",
    "\n",
    "# Get predictions and true labels\n",
    "predictions, true_labels = evaluate(model, test_loader)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "\n",
    "# Create a pandas DataFrame from the confusion matrix\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=class_names, columns=class_names)\n",
    "\n",
    "# Display the confusion matrix as a DataFrame with class names as labels\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(conf_matrix_df)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predictions, target_names=class_names))\n",
    "import seaborn as sn\n",
    "y_true=['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise']\n",
    "data = conf_matrix\n",
    "df_cm = pd.DataFrame(data, columns=np.unique(y_true), index = np.unique(y_true))\n",
    "sn.set(font_scale=2)#for label size\n",
    "sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 24}, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BanglaEmotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "from transformers import BertForSequenceClassification,BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('sagorsarker/bangla-bert-base')\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\"sagorsarker/bangla-bert-base\", num_labels=6)\n",
    "\n",
    "df=pd.read_csv(\"train.csv\")\n",
    "corpus = df['text'].to_list()\n",
    "y=df['class']\n",
    "df2 = pd.read_csv(\"test.csv\")\n",
    "corpus2 = df2['text'].to_list()\n",
    "y2=df2['class']\n",
    "corpus.extend(corpus2)\n",
    "y = pd.concat([y,y2])\n",
    "end = 4700\n",
    "train_texts = corpus[0:end]\n",
    "test_texts = corpus[end:]\n",
    "train_labels = y[0:end].to_list()\n",
    "test_labels = y[end:].to_list()\n",
    "#texts = df[\"t\"]\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.1, random_state=42)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_labels)\n",
    "val_labels = label_encoder.transform(val_labels)\n",
    "test_labels = label_encoder.transform(test_labels)\n",
    "\n",
    "# Tokenization\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=140)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=140)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=140)\n",
    "\n",
    "# Convert to PyTorch datasets\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = EmotionDataset(train_encodings, train_labels)\n",
    "val_dataset = EmotionDataset(val_encodings, val_labels)\n",
    "test_dataset = EmotionDataset(test_encodings, test_labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define model\n",
    "num_labels = len(np.unique(train_labels))\n",
    "\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "epochs = 20\n",
    "optim = AdamW(model.parameters(), lr=5e-5)\n",
    "total_steps = len(train_loader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optim, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "def train(model, loader, optim, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        optim.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device).long()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted_labels = torch.max(outputs.logits, dim=1)\n",
    "        correct_predictions += (predicted_labels == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    return total_loss / len(loader), accuracy\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "    total_loss = 0.0  # Initialize total loss\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Assume that model's output is a sequence classifier output with loss stored as outputs.loss\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()  # Accumulate the loss\n",
    "\n",
    "            # Convert predictions and labels for accuracy calculation\n",
    "            predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(loader)  # Calculate average loss\n",
    "    accuracy = accuracy_score(true_labels, predictions)  # Calculate accuracy\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "for epoch in range(epochs): \n",
    "    train_loss, train_accuracy = train(model, train_loader, optim, scheduler)\n",
    "    print(f'Epoch {epoch + 1}, Train_Loss: {round(train_loss,4)}, Train_Accuracy: {round(train_accuracy,4)}', end=\", \")\n",
    "\n",
    "    valid_loss, val_accuracy = evaluate(model, val_loader)\n",
    "    print(f'Val_Loss: {round(valid_loss,4)}, Val_Accuracy: {round(val_accuracy,4)}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Evaluate model\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].numpy()  # CPU\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
    "            true_labels.extend(labels)\n",
    "\n",
    "    return predictions, true_labels\n",
    "\n",
    "# Get predictions and true labels\n",
    "predictions, true_labels = evaluate(model, test_loader)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "\n",
    "# Create a pandas DataFrame from the confusion matrix\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=class_names, columns=class_names)\n",
    "\n",
    "# Display the confusion matrix as a DataFrame with class names as labels\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(conf_matrix_df)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_labels, predictions, target_names=class_names))\n",
    "import seaborn as sn\n",
    "y_true=['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise']\n",
    "data = conf_matrix\n",
    "df_cm = pd.DataFrame(data, columns=np.unique(y_true), index = np.unique(y_true))\n",
    "sn.set(font_scale=2)#for label size\n",
    "sn.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 24}, fmt=\"d\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
